{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Particle Swarm Optimization (PSO) implementation for training the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We calculate the constants related to the quantizer and the distortions.\n",
    "\n",
    "# 79-character line limit\n",
    "######### ######### ######### ######### ######### ######### ######### #########\n",
    "\n",
    "%reset -f\n",
    "\n",
    "import numpy as np # The NumPy library\n",
    "#import math # The math module, np includes it\n",
    "from scipy.integrate import quad # Method for integration in scipy.integrate sub-package\n",
    "\n",
    "\n",
    "cells_num = 128\n",
    "# The opitimized spaces for a Guassian distribution in a uniform quantizer(UQ).\n",
    "# The sizes are for UQs for number of cells: 4, 8, 16, 32, 64, 128, 256.\n",
    "all_size_gaus = np.array([0.9957, 0.5860, 0.3352, 0.1881, 0.1041, 0.0569, 0.0308])\n",
    "\n",
    "cell_size = all_size_gaus[int(np.log2(cells_num))-2]\n",
    "\n",
    "# np.arange has rounding error issue.\n",
    "# boundaries_symm = np.arange(-(cells_num/2-1) * cell_size, # For symmetric distributions\n",
    "#                              (cells_num/2) * cell_size,\n",
    "#                             cell_size) \n",
    "\n",
    "boundaries_symm = np.linspace(-(cells_num/2-1) * cell_size, # For symmetric distributions\n",
    "                               (cells_num/2-1) * cell_size,\n",
    "                              cells_num-1)\n",
    "n_inf = float(\"-inf\")\n",
    "p_inf = float(\"inf\")\n",
    "\n",
    "boundaries_symm = np.insert(boundaries_symm, 0, n_inf)\n",
    "boundaries_symm = np.append(boundaries_symm, p_inf)\n",
    "\n",
    "def pdf(x): # Defining the distribution\n",
    "    gaus_std = 1\n",
    "    gaus_mean = 0\n",
    "    pdf = 1/(gaus_std*np.sqrt(2*np.pi)) * \\\n",
    "                  np.exp(-0.5*((x-gaus_mean)/gaus_std)**2) # Gaussian pdf\n",
    "    return pdf\n",
    "\n",
    "def xpdf(x):\n",
    "    xpdf = x * pdf(x)\n",
    "    return xpdf\n",
    "\n",
    "def x2pdf (x):\n",
    "    x2pdf = x * xpdf(x)\n",
    "    return x2pdf\n",
    "\n",
    "prbs = []\n",
    "xprbs = []\n",
    "x2prbs = []\n",
    "cell_reps = []\n",
    "for i in range (0, cells_num):\n",
    "    cell_prb, integ_err = quad(pdf, boundaries_symm[i], boundaries_symm[i+1])\n",
    "    prbs = np.append(prbs, cell_prb)\n",
    "    \n",
    "    cell_xprb, integ_err = quad(xpdf, boundaries_symm[i], boundaries_symm[i+1])\n",
    "    xprbs = np.append(xprbs, cell_xprb)\n",
    "    \n",
    "    cell_x2prb, integ_err = quad(x2pdf, boundaries_symm[i], boundaries_symm[i+1])\n",
    "    x2prbs = np.append(x2prbs, cell_x2prb)\n",
    "    \n",
    "    cell_rep = cell_xprb / cell_prb\n",
    "    cell_reps = np.append(cell_reps, cell_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_size = 128\n",
    "particles_num = 12800\n",
    "\n",
    "# We initialize the particles.\n",
    "W1 = np.random.randn(particles_num, l1_size, cells_num)\n",
    "B1 = np.random.randn(particles_num, l1_size)\n",
    "W2 = np.random.randn(particles_num, cells_num, l1_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6302091486928542\n"
     ]
    }
   ],
   "source": [
    "# We define the activation functions.\n",
    "def relu(x):\n",
    "    return np.maximum(0,x)\n",
    "\n",
    "def lrelu(x):\n",
    "    return np.where(x > 0, x, x * 0.1)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "distortions = []\n",
    "for i in range (particles_num):\n",
    "    l1_outs = relu(np.dot(W1[i], cell_reps)+B1[i])\n",
    "    l2_outs = np.dot(W2[i], l1_outs)\n",
    "    l2_outs = np.round(l2_outs, 16)\n",
    "\n",
    "    # We assigned the indexes based on the final layer outputs.\n",
    "    sorted_outs = np.sort(l2_outs)\n",
    "    indexes = []\n",
    "    for i in range(0, cells_num):\n",
    "        index = np.where(sorted_outs == l2_outs[i])\n",
    "        indexes = np.append(indexes, index)\n",
    "\n",
    "#     print(indexes)\n",
    "\n",
    "    yijs = [] # Yijs based on the assigned indexes\n",
    "    dijs = []\n",
    "    for i in range(0, int(cells_num/2)):\n",
    "        j = i + cells_num/2\n",
    "        celli = np.where(indexes == i)\n",
    "        cellj = np.where(indexes == j)\n",
    "\n",
    "        yij = (xprbs[celli] + xprbs[cellj])/(prbs[celli] + prbs[cellj])\n",
    "        yijs = np.append(yijs, yij)\n",
    "\n",
    "        dij = x2prbs[celli] + yij**2 * prbs[celli] - yij *2 * xprbs[celli]\\\n",
    "            + x2prbs[cellj] + yij**2 * prbs[cellj] - yij *2 * xprbs[cellj]\n",
    "        dijs = np.append(dijs, dij)\n",
    "\n",
    "    distortion = np.round(sum(dijs), 16) # The Eve's distortion based on the assigned indexes\n",
    "\n",
    "    distortions = np.append(distortions, distortion)\n",
    "    \n",
    "# print(distortions)\n",
    "print(np.max(distortions))\n",
    "\n",
    "gb_pos = np.argmin(-distortions) # Global best particle\n",
    "gb_value = -distortions[gb_pos]\n",
    "\n",
    "gbW1 = W1[gb_pos]\n",
    "gbB1 = B1[gb_pos]\n",
    "gbW2 = W2[gb_pos]\n",
    "\n",
    "pbW1 = W1\n",
    "pbB1 = B1\n",
    "pbW2 = W2\n",
    "\n",
    "pb_value = -distortions\n",
    "\n",
    "last_VW1 = np.zeros([particles_num, l1_size, cells_num])\n",
    "last_VB1 = np.zeros([particles_num, l1_size])\n",
    "last_VW2 = np.zeros([particles_num, cells_num, l1_size])\n",
    "\n",
    "tW1 = W1.copy()\n",
    "tB1 = B1.copy()\n",
    "tW2 = W2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15. 12.  3.  9.  2.  8. 13.  6.  7.  1.  0. 10.  5. 11. 14.  4.]\n"
     ]
    }
   ],
   "source": [
    "######### ######### ######### ######### ######### ######### ######### #########\n",
    "iterations = 1000\n",
    "# inertia_weight = 0.9\n",
    "# c1 = 2 # cognitive_weight\n",
    "# c2 = 2 # global_weight\n",
    "\n",
    "# r1 = np.random.random()\n",
    "# r2 = np.random.random()\n",
    "\n",
    "VW1 = np.zeros([particles_num, l1_size, cells_num])\n",
    "VB1 = np.zeros([particles_num, l1_size])\n",
    "VW2 = np.zeros([particles_num, cells_num, l1_size])\n",
    "\n",
    "gb_values =[]\n",
    "\n",
    "rond = 1.5\n",
    "sigma = 4\n",
    "delta1 = 2.5\n",
    "delta2 = 0.5\n",
    "\n",
    "phi = 0.666\n",
    "tau = 0.6\n",
    "\n",
    "for m in range(0, iterations):\n",
    "    c1 = -rond * np.arctan(m/iterations*sigma)+delta1\n",
    "    c2 =  rond * np.arctan(m/iterations*sigma)+delta2\n",
    "    \n",
    "    inertia_weight = phi * np.cos((m/iterations)*np.pi)+tau\n",
    "#     print(c1)\n",
    "#     print(c2)\n",
    "#     print(inertia_weight)\n",
    "    \n",
    "    for n in range(0, particles_num):\n",
    "        r1 = np.random.random()\n",
    "        r2 = np.random.random()\n",
    "               \n",
    "\n",
    "        # We compute the new position.\n",
    "        VW1[n] = inertia_weight * last_VW1[n] + (c1 * r1 * (pbW1[n]-tW1[n]))\\\n",
    "             + (c2 * r2 * (gbW1-tW1[n]))\n",
    "        tW1[n] = tW1[n] + VW1[n]\n",
    "        last_VW1[n] = VW1[n] \n",
    "                 \n",
    "        VB1[n] = (inertia_weight * last_VB1[n]) + (c1 * r1 * (pbB1[n]-tB1[n]))\\\n",
    "              + (c2 * r2 * (gbB1 - tB1[n]))\n",
    "        tB1[n] = tB1[n] + VB1[n]\n",
    "        last_VB1[n] = VB1[n]\n",
    "                 \n",
    "        VW2[n] = (inertia_weight * last_VW2[n]) + (c1 * r1 * (pbW2[n]-tW2[n]))\\\n",
    "              + (c2 * r2 * (gbW2 - tW2[n]))\n",
    "        tW2[n] =tW2[n] + VW2[n]\n",
    "        last_VW2[n] = VW2[n] \n",
    "        \n",
    "        l1_outs = []\n",
    "        l2_outs = []\n",
    "        # Now we compute the new distortion.\n",
    "        l1_outs = relu(np.dot(tW1[n], cell_reps)+tB1[n])\n",
    "        l2_outs = np.dot(tW2[n], l1_outs)\n",
    "        l2_outs = np.round(l2_outs, 16)\n",
    "        \n",
    "        for p in range(0, cells_num-1):\n",
    "            for q in range (p+1, cells_num):\n",
    "                if l2_outs[p] == l2_outs[q]:\n",
    "                    l2_outs[q] += np.random.rand(1,1)-0.5\n",
    "\n",
    "        sorted_outs = np.sort(l2_outs)\n",
    "        indexes = []\n",
    "        for i in range(0, cells_num):\n",
    "            index = np.where(sorted_outs == l2_outs[i])\n",
    "            indexes = np.append(indexes, index)\n",
    "\n",
    "        yijs = [] # Yijs based on the assigned indexes\n",
    "        dijs = []\n",
    "        for i in range(0, int(cells_num/2)):\n",
    "            j = i + cells_num/2\n",
    "            celli = np.where(indexes == i)\n",
    "            cellj = np.where(indexes == j)\n",
    "\n",
    "            yij = (xprbs[celli] + xprbs[cellj])/(prbs[celli] + prbs[cellj])\n",
    "            yijs = np.append(yijs, yij)\n",
    "\n",
    "            dij = x2prbs[celli] + yij**2 * prbs[celli] - yij *2 * xprbs[celli]\\\n",
    "                + x2prbs[cellj] + yij**2 * prbs[cellj] - yij *2 * xprbs[cellj]\n",
    "            dijs = np.append(dijs, dij)\n",
    "\n",
    "        distortion = np.round(sum(dijs), 16) # The Eve's distortion based on the assigned indexes\n",
    "                         \n",
    "        if -distortion < pb_value[n]:\n",
    "            pbW1[n] = W1[n]\n",
    "            pbB1[n] = B1[n]\n",
    "            pbW2[n] = W2[n]\n",
    "            pb_value[n] = -distortion\n",
    "        \n",
    "        if -distortion < gb_value:\n",
    "            gbW1 = W1[n]\n",
    "            gbB1 = B1[n]\n",
    "            gbW2 = W2[n]\n",
    "            gb_value = -distortion\n",
    "            gb_values = np.append(gb_values, gb_value)\n",
    "            best_indexes = indexes\n",
    "            \n",
    "            print(gb_value)        \n",
    "        #print(distortion)\n",
    "#         if distortion >= 1:\n",
    "#             print(indexes)\n",
    "\n",
    "# print(gb_values)\n",
    "print(best_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
